{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using snakemake to highlight changes in multiple protein-protein interactions via PDBsum data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook builds on some of the basics covered in [Using PDBsum data to highlight changes in protein-protein interactions](Using%20PDBsum%20data%20to%20highlight%20changes%20in%20protein-protein%20interactions.ipynb) in order to compare many combinations of protein-protein interactions of pairs of proteins in different structures.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous notebook, [Using PDBsum data to highlight changes in protein-protein interactions](Using%20PDBsum%20data%20to%20highlight%20changes%20in%20protein-protein%20interactions.ipynb), stepped through making reports about the interactions between two chains as they occur in two different, related structures.  \n",
    "Is there a way to scale this up to make reports for many chains in several pairs of related structures? This may be especially helpful for the cases where the structures involved are large complexes and several pairs are of interest, such as all those pairs contributing interactions in a region of interest for a researcher.\n",
    "\n",
    "This notebook spells out a way to do this with minimal effort. In fact, you only need knowledge of the PDB code identifiers of the structures you are interested in and the chain designations in each structure. You'll fill out a table to define the structures and chains and kick of the process and make Jupyter notebooks containing the reports for pair of protein-protein interactions.\n",
    "\n",
    "-----\n",
    "\n",
    "**Step #1:** Make a table with columns separated by spaces and each line as a row. Each row will specify two structures and two chains from each of those structures, for a total of six items per line. The order on each line is important. You'll want to specify structure #1 followed by the two chain designations to examine interactions between and then on the rest of the line the other PDB code for structure number #2 followed by the chain designations that correspond to the same order as the prior half of  the line. The following illustrates the content of such a table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "6kiv N R 6kiz N R\n",
    "6kiv N R 6kix N R\n",
    "6kiz N R 6kix N R\n",
    "6kiv K N 6kiz K N\n",
    "6kiv K N 6kix K N\n",
    "6kiv R K 6kiz R K\n",
    "6kiv R K 6kix R K\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can open a text file in Jupyter and directly edit the file to make your table. For the sake of the demostration, this will be done using the notebook below.\n",
    "\n",
    "Iif it helps you can think about the columns here for each line as the following, using the nomeclature from the first few code cells of previous notebook, [Using PDBsum data to highlight changes in protein-protein interactions](Using%20PDBsum%20data%20to%20highlight%20changes%20in%20protein-protein%20interactions.ipynb).\n",
    "\n",
    "```text\n",
    "structure1 structure1_chain1 structure1_chain2 structure2 structure2_chain1 structure2_chain2\n",
    "```\n",
    "\n",
    "**Step #2:** Save the table with the following name, `int_matrix.txt`. It has to have that name for the table to recognized and processed to make the Jupyter notbeook files with the reports.\n",
    "\n",
    "The following will do that here using this notebook; however, you can, and will want to, skip running this if already made your own table. If you run it, it will replace your file though. Alternatively, you can edit the code below to make a table with the contents that interest you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 's' (str) to file 'int_matrix.txt'.\n"
     ]
    }
   ],
   "source": [
    "s='''6kiv N R 6kiz N R\n",
    "6kiv N R 6kix N R\n",
    "6kiz N R 6kix N R\n",
    "6kiv K N 6kiz K N\n",
    "6kiv K N 6kix K N\n",
    "6kiv R K 6kiz R K\n",
    "6kiv R K 6kix R K\n",
    "'''\n",
    "%store s >int_matrix.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step #3:** Run snakemake and it will process the `int_matrix.txt` file to extract the information and make individual notebooks corresponding to analysis of the interactions for each line. This will be very similar to running the previous notebooks in this series with the items spelled out on each line.  \n",
    "The file snakemake uses by default, named `Snakefile`, is already here and that is what will run when the next command is executed.  \n",
    "It will take about a minute or less to complete if you are running the demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mBuilding DAG of jobs...\u001b[0m\n",
      "\u001b[33mUsing shell: /bin/bash\u001b[0m\n",
      "\u001b[33mProvided cores: 1 (use --cores to define parallelism)\u001b[0m\n",
      "\u001b[33mRules claiming more threads will be scaled down.\u001b[0m\n",
      "\u001b[33mJob counts:\n",
      "\tcount\tjobs\n",
      "\t1\tall\n",
      "\t7\tconvert_scripts_to_nb_and_run_using_jupytext\n",
      "\t1\tmake_archive\n",
      "\t1\tread_table_and_create_py\n",
      "\t10\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 22 01:59:13 2021]\u001b[0m\n",
      "\u001b[32mrule read_table_and_create_py:\n",
      "    input: int_matrix.txt\n",
      "    output: interactions_report_for_6kiv_N_R_6kiz_N_R.py, interactions_report_for_6kiv_N_R_6kix_N_R.py, interactions_report_for_6kiz_N_R_6kix_N_R.py, interactions_report_for_6kiv_K_N_6kiz_K_N.py, interactions_report_for_6kiv_K_N_6kix_K_N.py, interactions_report_for_6kiv_R_K_6kiz_R_K.py, interactions_report_for_6kiv_R_K_6kix_R_K.py\n",
      "    jobid: 3\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[33mJob counts:\n",
      "\tcount\tjobs\n",
      "\t1\tread_table_and_create_py\n",
      "\t1\u001b[0m\n",
      "\u001b[32m[Fri Jan 22 01:59:14 2021]\u001b[0m\n",
      "\u001b[32mFinished job 3.\u001b[0m\n",
      "\u001b[32m1 of 10 steps (10%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 22 01:59:14 2021]\u001b[0m\n",
      "\u001b[32mrule convert_scripts_to_nb_and_run_using_jupytext:\n",
      "    input: interactions_report_for_6kiz_N_R_6kix_N_R.py\n",
      "    output: interactions_report_for_6kiz_N_R_6kix_N_R.ipynb\n",
      "    jobid: 5\n",
      "    wildcards: details=6kiz_N_R_6kix_N_R\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "[jupytext] Reading interactions_report_for_6kiz_N_R_6kix_N_R.py in format py\n",
      "[jupytext] Executing notebook with kernel python3\n",
      "[jupytext] Writing interactions_report_for_6kiz_N_R_6kix_N_R.ipynb\n",
      "\u001b[32m[Fri Jan 22 01:59:21 2021]\u001b[0m\n",
      "\u001b[32mFinished job 5.\u001b[0m\n",
      "\u001b[32m2 of 10 steps (20%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 22 01:59:21 2021]\u001b[0m\n",
      "\u001b[32mrule convert_scripts_to_nb_and_run_using_jupytext:\n",
      "    input: interactions_report_for_6kiv_K_N_6kix_K_N.py\n",
      "    output: interactions_report_for_6kiv_K_N_6kix_K_N.ipynb\n",
      "    jobid: 7\n",
      "    wildcards: details=6kiv_K_N_6kix_K_N\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "[jupytext] Reading interactions_report_for_6kiv_K_N_6kix_K_N.py in format py\n",
      "[jupytext] Executing notebook with kernel python3\n",
      "[jupytext] Writing interactions_report_for_6kiv_K_N_6kix_K_N.ipynb\n",
      "\u001b[32m[Fri Jan 22 01:59:26 2021]\u001b[0m\n",
      "\u001b[32mFinished job 7.\u001b[0m\n",
      "\u001b[32m3 of 10 steps (30%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 22 01:59:26 2021]\u001b[0m\n",
      "\u001b[32mrule convert_scripts_to_nb_and_run_using_jupytext:\n",
      "    input: interactions_report_for_6kiv_R_K_6kix_R_K.py\n",
      "    output: interactions_report_for_6kiv_R_K_6kix_R_K.ipynb\n",
      "    jobid: 9\n",
      "    wildcards: details=6kiv_R_K_6kix_R_K\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "[jupytext] Reading interactions_report_for_6kiv_R_K_6kix_R_K.py in format py\n",
      "[jupytext] Executing notebook with kernel python3\n",
      "[jupytext] Writing interactions_report_for_6kiv_R_K_6kix_R_K.ipynb\n",
      "\u001b[32m[Fri Jan 22 01:59:31 2021]\u001b[0m\n",
      "\u001b[32mFinished job 9.\u001b[0m\n",
      "\u001b[32m4 of 10 steps (40%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 22 01:59:31 2021]\u001b[0m\n",
      "\u001b[32mrule convert_scripts_to_nb_and_run_using_jupytext:\n",
      "    input: interactions_report_for_6kiv_N_R_6kiz_N_R.py\n",
      "    output: interactions_report_for_6kiv_N_R_6kiz_N_R.ipynb\n",
      "    jobid: 2\n",
      "    wildcards: details=6kiv_N_R_6kiz_N_R\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "[jupytext] Reading interactions_report_for_6kiv_N_R_6kiz_N_R.py in format py\n",
      "[jupytext] Executing notebook with kernel python3\n",
      "[jupytext] Writing interactions_report_for_6kiv_N_R_6kiz_N_R.ipynb\n",
      "\u001b[32m[Fri Jan 22 01:59:36 2021]\u001b[0m\n",
      "\u001b[32mFinished job 2.\u001b[0m\n",
      "\u001b[32m5 of 10 steps (50%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 22 01:59:36 2021]\u001b[0m\n",
      "\u001b[32mrule convert_scripts_to_nb_and_run_using_jupytext:\n",
      "    input: interactions_report_for_6kiv_N_R_6kix_N_R.py\n",
      "    output: interactions_report_for_6kiv_N_R_6kix_N_R.ipynb\n",
      "    jobid: 4\n",
      "    wildcards: details=6kiv_N_R_6kix_N_R\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "[jupytext] Reading interactions_report_for_6kiv_N_R_6kix_N_R.py in format py\n",
      "[jupytext] Executing notebook with kernel python3\n",
      "[jupytext] Writing interactions_report_for_6kiv_N_R_6kix_N_R.ipynb\n",
      "\u001b[32m[Fri Jan 22 01:59:41 2021]\u001b[0m\n",
      "\u001b[32mFinished job 4.\u001b[0m\n",
      "\u001b[32m6 of 10 steps (60%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 22 01:59:41 2021]\u001b[0m\n",
      "\u001b[32mrule convert_scripts_to_nb_and_run_using_jupytext:\n",
      "    input: interactions_report_for_6kiv_K_N_6kiz_K_N.py\n",
      "    output: interactions_report_for_6kiv_K_N_6kiz_K_N.ipynb\n",
      "    jobid: 6\n",
      "    wildcards: details=6kiv_K_N_6kiz_K_N\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "[jupytext] Reading interactions_report_for_6kiv_K_N_6kiz_K_N.py in format py\n",
      "[jupytext] Executing notebook with kernel python3\n",
      "[jupytext] Writing interactions_report_for_6kiv_K_N_6kiz_K_N.ipynb\n",
      "\u001b[32m[Fri Jan 22 01:59:46 2021]\u001b[0m\n",
      "\u001b[32mFinished job 6.\u001b[0m\n",
      "\u001b[32m7 of 10 steps (70%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 22 01:59:46 2021]\u001b[0m\n",
      "\u001b[32mrule convert_scripts_to_nb_and_run_using_jupytext:\n",
      "    input: interactions_report_for_6kiv_R_K_6kiz_R_K.py\n",
      "    output: interactions_report_for_6kiv_R_K_6kiz_R_K.ipynb\n",
      "    jobid: 8\n",
      "    wildcards: details=6kiv_R_K_6kiz_R_K\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "[jupytext] Reading interactions_report_for_6kiv_R_K_6kiz_R_K.py in format py\n",
      "[jupytext] Executing notebook with kernel python3\n",
      "[jupytext] Writing interactions_report_for_6kiv_R_K_6kiz_R_K.ipynb\n",
      "\u001b[32m[Fri Jan 22 01:59:51 2021]\u001b[0m\n",
      "\u001b[32mFinished job 8.\u001b[0m\n",
      "\u001b[32m8 of 10 steps (80%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 22 01:59:51 2021]\u001b[0m\n",
      "\u001b[32mrule make_archive:\n",
      "    input: interactions_report_for_6kiv_N_R_6kiz_N_R.ipynb, interactions_report_for_6kiv_N_R_6kix_N_R.ipynb, interactions_report_for_6kiz_N_R_6kix_N_R.ipynb, interactions_report_for_6kiv_K_N_6kiz_K_N.ipynb, interactions_report_for_6kiv_K_N_6kix_K_N.ipynb, interactions_report_for_6kiv_R_K_6kiz_R_K.ipynb, interactions_report_for_6kiv_R_K_6kix_R_K.ipynb\n",
      "    output: interactions_report_nbsJan2220210159.tar.gz\n",
      "    jobid: 1\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "Be sure to download interactions_report_nbsJan2220210159.tar.gz.\n",
      "\u001b[32m[Fri Jan 22 01:59:51 2021]\u001b[0m\n",
      "\u001b[32mFinished job 1.\u001b[0m\n",
      "\u001b[32m9 of 10 steps (90%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 22 01:59:51 2021]\u001b[0m\n",
      "\u001b[32mlocalrule all:\n",
      "    input: interactions_report_nbsJan2220210159.tar.gz\n",
      "    jobid: 0\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 22 01:59:51 2021]\u001b[0m\n",
      "\u001b[32mFinished job 0.\u001b[0m\n",
      "\u001b[32m10 of 10 steps (100%) done\u001b[0m\n",
      "\u001b[33mComplete log: /home/jovyan/notebooks/.snakemake/log/2021-01-22T015912.634684.snakemake.log\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!snakemake --cores 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(For those knowlegeable with snakemake, I will say that I set the number of cores as one because I was finding with eight that occasionally a race condition would ensue where some of the auxillary scripts by notebooks would overwrite each other as they was being accessed by another notebook causing failures. Using one core avoids that hazard. I will add though that in most cases if you use multiple cores, you can easily get the additional files and a new archive made by running snakemake with your chosen number of cores again.  I never saw a race hazard with my clean rule, and so if you want to quickly start over you can run `!snakemake --cores 8 clean`.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step #4:** Verify the Jupyter notebooks with the reports were generated.  \n",
    "You can go to the dashboard and see the ouput of running snakemake. To do that click on the Jupyter logo in the upper left top of this notebook and on that page you'll look in  the notebooks directory and you should see files that begin with `interactions_report_` and end with `.ipynb`. You can examine some of them to insure all is as expected.\n",
    "\n",
    "If things seem to be working and you haven't run your data yet, run `!snakemake --cores 8 clean` in a cell to reset things, and then edit & save `int_matrix.txt` to have your information, and then run the `!snakemake --cores 1` step above, again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step #5:** If this was anyting other than the demonstration run, download the archive containing all the Jupyter notebooks bundled together.  \n",
    "For ease in downloading, all the created notebooks have been saved as a compressed archive so that you only need to retieve and keep track of one file. The file you are looking for begins with `interactions_report_nbs` in front of a date/time stamp and ends with `.tar.gz`. The snakemake run will actually highlight this archive towards the very bottom of the run, following the words 'Be sure to download'.  \n",
    "**Download that file from this remote, temporary session to your local computer.** You should see this archive file ending in `.tar.gz` on the dashboard. Toggle next to it to select it and then select `Download` to bring it from the remote Jupyterhub session to your computer. If you don't retieve that file and the session ends, you'll need to re-run to get the results again.\n",
    "\n",
    "You should be able to unpack that archive using your favorite software to extract compressed files. If that is proving difficult, you can always reopen a session like you did to run this series of notebooks and upload the archive and then run the following command in a Jupyter notebook cellk to unpack it:\n",
    "\n",
    "```bash\n",
    "!tar xzf interactions_report_nbs*\n",
    "```\n",
    "\n",
    "(If you are running that command on the command line, leave off the exclamation book.)\n",
    "You can then examine the files in the session or download the individual Jupyter notebooks similar to the advice on how to download the archive given above.\n",
    "\n",
    "In the next notebook in this series, [Making the multiple reports generated via snakemake clearer by adding protein names](Making%20the%20multiple%20reports%20generated%20via%20snakemake%20clearer%20by%20adding%20protein%20names.ipynb), I work through how to make the reports more human readable by swapping the chain designations with the actual names of the proteins. This is similar to making the report more human readable that was discussed at the bottom of the previous notebook, [Using PDBsum data to highlight changes in protein-protein interactions](Using%20PDBsum%20data%20to%20highlight%20changes%20in%20protein-protein%20interactions.ipynb); however, it will be done to all the notebooks at once based on the file name beginning with `interactions_report_for_` and ending with `.ipynb`.\n",
    "\n",
    "-----\n",
    "\n",
    "Please continue on with the next notebook in this series, [Making the multiple reports generated via snakemake clearer by adding protein names](Making%20the%20multiple%20reports%20generated%20via%20snakemake%20clearer%20by%20adding%20protein%20names.ipynb).\n",
    "\n",
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
